# lbplayground
Note: The refractoring would be done for this readme.md using LLM(for formatting and correction)

## ğŸ“Œ Action Plan
This project will serve as a structured playground to experiment with modern data engineering and analytics practices. The focus areas will include:
- Setup CI/CD (Dev git Actions for code reviews/pr/quality etc)
- Containerization skeleton (for different tech stack)  
- Implementation and local testing for the skeleton of the tech stack  
- Analysis of dataset through Metabase and direct inferences  
- Data dictionary understanding â€“ Dimensional/Fact or DL/Layer, or relevant feasible requirements (modelling understanding)  
- Airflow infra setup  
- Development Governance tags inside Airflow  
- Data Goverance (I mean we have limited time but we can try to cover some stuff)
- Data Quality (Great Expectation)
- DuckDB infra setup  (maybe polars but seems like duckdb is recommendation)
- Metabase report (KPIs on top of SQL queries or required exploratory questions reports)  
- Recreatable reports/dashboards that can be manipulated or viewed by end users
- Writing some more things here later.  
Perfect ğŸ‘ thanks for sharing your original `README.md`.
Iâ€™ve blended it with the polished one I drafted earlier, keeping **all your points** (tech stack, action plan, DAG execution checks, Q\&A results, troubleshooting notes).


---
# ğŸ§ ListenBrainz Data Engineering Playground (`lbplayground`)

This project implements a **production-style data engineering pipeline** for the [ListenBrainz](https://listenbrainz.org/) dataset, using modern open-source tools for orchestration, analytics, and visualization.
It is designed as both a **learning playground** and a **demonstration of best practices** (idempotent pipelines, SCD2, snapshotting, reporting marts).

---

## âš™ï¸ Tech Stack

* **Python** â€“ scripting and ETL
* **SQL** â€“ transformations and modeling
* **GitHub / GitHub Actions** â€“ version control & CI/CD
* **Docker / Docker Compose** â€“ reproducible environments
* **Apache Airflow** â€“ orchestration (DAG-based workflows)
* **DuckDB** â€“ embedded analytics database
* **Metabase** â€“ BI dashboards (need to resolve the JAR file to display the analytics)
* **Great Expectations** (optional) â€“ data quality

---

## ğŸ“Œ Action Plan

This repo demonstrates:

* âœ… Containerization skeleton (Airflow, DuckDB, Metabase)
* âœ… Data orchestration with **Airflow DAGs**
* âœ… **Raw â†’ Staging â†’ Curated â†’ Marts â†’ Reporting** layered architecture
* âœ… Idempotent SQL transformations (safe re-runs)
* âœ… **Slowly Changing Dimension Type 2 (SCD2)** for user names
* âœ… Daily **snapshotting** of active users
* âœ… **Metabase dashboards** with DuckDB JDBC driver
* âœ… Optional **data quality checks** (Great Expectations)
* âœ… CI/CD foundations (GitHub Actions, code review hooks)

---

## ğŸ—ï¸ Architecture

### Data Layers

* **Raw** â€“ JSONL ingestion into `raw.listens_jsonl`
* **Staging** â€“ Flattened tables (`staging.listens_flat`)
* **Curated** â€“ `dim_user` (SCD2), `fact_listen`, `snapshots_user_activity`
* **Marts** â€“ `mart_user_activity`, `mart_track_performance`
* **Reporting** â€“ SQL views answering exploratory questions

### Orchestration

* `dag_raw_ingest` â€“ raw ingestion
* `dag_staging_curated` â€“ staging + curated
* `dag_marts_reporting` â€“ marts + reporting

### BI Integration

* **Read-write DB**: `lb.duckdb` (Airflow writes)
* **Read-only DB**: `lb_ro.duckdb` (Metabase reads) â†’ avoids file lock conflicts

---

## ğŸš€ Setup

### 1. Clone repo

```bash
git clone https://github.com/shafaypro/lbplayground.git
cd lbplayground
```

### 2. Create `.env`

```env
DUCKDB_PATH=/opt/duckdb/warehouse/lb.duckdb
DATA_GLOB=/opt/data/*.jsonl
SOURCE_FILTER=spotify
AIRFLOW__CORE__LOAD_EXAMPLES=False
```

### 3. Start containers

```bash
docker compose up -d --build
```

Services:

* Airflow â†’ [http://localhost:8080](http://localhost:8080) (admin/admin)
* Metabase â†’ [http://localhost:3000](http://localhost:3000)

### 4. Load data

Place your dataset (`ds.jsonl`) into `./data/`.


## â–¶ï¸ DAG Execution

1. Run `dag_raw_ingest` â†’ loads `ds.jsonl` into `raw.listens_jsonl`
2. Run `dag_staging_curated` â†’ builds staging + curated layers
3. Run `dag_marts_reporting` â†’ builds marts + reporting views

---

---

## ğŸ” Verify DuckDB

Since DuckDB is stored in a **Docker volume**, you wonâ€™t see `lb.duckdb` in your repo.
To check inside Airflow:

```bash
docker exec -it lbplayground_airflow_web python
```

```python
import duckdb
con = duckdb.connect("/opt/duckdb/warehouse/lb.duckdb")
print(con.execute("SHOW TABLES").fetchall())
print(con.execute("SELECT COUNT(*) FROM raw.listens_jsonl").fetchall())
```

---


## â“ Exploratory Questions

### a) User activity

* **Top 10 users by listens**:

  ```
  [('hds', 46885), ('Groschi', 14959), ('Silent Singer', 13005), ('phdnk', 12861), ...]
  ```
* **How many users listened on 1st March 2019?**
  â†’ `75`
* **First song per user?**
  â†’ Query provided (`report_first_song_per_user.sql`)

### b) Top 3 days per user

* 3 rows per user
* Columns: `(user, number_of_listens, date)`
* Sorted by user and listens

### c) Rolling active users (optional)

* Daily absolute number of active users
* Percentage of active users
* Lookback = 7 days (`X-6 to X`)

All queries exist under `airflow/sql/reporting/*.sql`.

---

## ğŸ“Š Metabase

1. Copy DuckDB JDBC driver to `./metabase_plugins/`.
2. Start Metabase with:

   ```yaml
   volumes:
     - ./metabase_plugins:/plugins
     - duckdb_warehouse:/duck
   environment:
     MB_PLUGINS_DIR: /plugins
   ```
3. Connect DB in Metabase:

   * Database type: DuckDB
   * File path: `/duck/lb_ro.duckdb`

---

## ğŸ› ï¸ Troubleshooting

* **DuckDB lock error** â†’ use `lb_ro.duckdb` for BI
* **SQL schema empty** â†’ check Airflow task logs (`docker logs lbplayground_airflow_scheduler`)
* **Driver not visible in Metabase** â†’ ensure `.jar` is in `/plugins` inside container



* **Modern data engineering practices** (Airflow, DuckDB, Metabase)
* **Layered modeling** (raw â†’ staging â†’ curated â†’ marts â†’ reporting)
* **Governance**: CI/CD, idempotency, SCD2, snapshotting
* **End-to-end visibility**: From ingestion â†’ transformation â†’ BI dashboards
