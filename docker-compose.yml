name: lbplayground

services:
  postgres:
    image: postgres:15
    container_name: lbplayground_postgres
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: airflow_db
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  airflow-init:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: lbplayground_airflow_init
    depends_on:
      - postgres
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:secret@postgres:5432/airflow_db
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/sql:/opt/airflow/sql
      - ./data:/opt/data
      - duckdb_warehouse:/opt/duckdb/warehouse
    command: >
      bash -c "
        mkdir -p /opt/duckdb/warehouse &&
        chown -R airflow /opt/duckdb/warehouse &&
        airflow db migrate &&
        airflow users create --username admin --password admin --role Admin --firstname Air --lastname Flow --email admin@example.com || true
      "

  airflow-webserver:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: lbplayground_airflow_web
    restart: always
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:secret@postgres:5432/airflow_db
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/sql:/opt/airflow/sql
      - ./data:/opt/data
      - duckdb_warehouse:/opt/duckdb/warehouse
    command: >
      bash -c "
        mkdir -p /opt/duckdb/warehouse &&
        chown -R airflow /opt/duckdb/warehouse &&
        airflow webserver
      "

  airflow-scheduler:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: lbplayground_airflow_scheduler
    restart: always
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:secret@postgres:5432/airflow_db
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/sql:/opt/airflow/sql
      - ./data:/opt/data
      - duckdb_warehouse:/opt/duckdb/warehouse
    command: >
      bash -c "
        mkdir -p /opt/duckdb/warehouse &&
        chown -R airflow /opt/duckdb/warehouse &&
        airflow scheduler
      "

  # metabase:
  #   image: metabase/metabase:latest
  #   container_name: lbplayground_metabase
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     MB_PLUGINS_DIR: /plugins
  #   volumes:
  #     - metabase_data:/metabase-data
  #     - duckdb_warehouse:/duck
  #     - ./metabase_plugins:/plugins

  streamlit:
    image: python:3.11-slim
    container_name: lbplayground_streamlit
    working_dir: /app
    ports:
      - "8501:8501"
    volumes:
      - ./streamlit_app:/app
      - duckdb_warehouse:/duck
      - duckdb_warehouse:/opt/duckdb/warehouse

    command: >
      bash -c "
        pip install streamlit duckdb pandas plotly &&
        streamlit run app.py --server.address=0.0.0.0
      "



volumes:
  pgdata:
  duckdb_warehouse:
  # metabase_data:
